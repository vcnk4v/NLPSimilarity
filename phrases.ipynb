{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vyakhya/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/vyakhya/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "# python3 -m spacy download en_core_web_sm\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "# %pip install datasets\n",
    "import numpy as np\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import datasets\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained word embeddings (Word2Vec)\n",
    "word2vec_model_path_pretrained = 'models/GoogleNews-vectors-negative300.bin.gz'\n",
    "word2vec_model_pretrained = KeyedVectors.load_word2vec_format(word2vec_model_path_pretrained, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 1.42M/1.42M [00:02<00:00, 616kB/s]\n",
      "Downloading data: 100%|██████████| 202k/202k [00:00<00:00, 243kB/s]\n",
      "Downloading data: 100%|██████████| 403k/403k [00:01<00:00, 373kB/s]\n",
      "Generating train split: 100%|██████████| 7004/7004 [00:00<00:00, 228756.46 examples/s]\n",
      "Generating validation split: 100%|██████████| 1000/1000 [00:00<00:00, 388613.36 examples/s]\n",
      "Generating test split: 100%|██████████| 2000/2000 [00:00<00:00, 622485.01 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"PiC/phrase_similarity\")\n",
    "train_data = dataset[\"train\"]\n",
    "validation_dataset = dataset[\"validation\"]\n",
    "test_data = dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def get_phrase_embedding(phrase, word_embeddings):\n",
    "    doc = nlp(phrase)\n",
    "    embeddings = [word_embeddings[token.text] if token.text in word_embeddings else np.zeros(word_embeddings.vector_size) for token in doc]\n",
    "    if embeddings:\n",
    "        return np.mean(embeddings, axis=0)\n",
    "    else:\n",
    "        return np.zeros(word_embeddings.vector_size)\n",
    "\n",
    "def phrase_similarity(phrase1, phrase2, word_embeddings):\n",
    "    embedding1 = get_phrase_embedding(phrase1, word_embeddings)\n",
    "    embedding2 = get_phrase_embedding(phrase2, word_embeddings)\n",
    "    if np.any(embedding1) and np.any(embedding2):\n",
    "        similarity = cosine_similarity([embedding1], [embedding2])[0][0]\n",
    "        return similarity\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def cosine_phrase_similarity(phrase1, phrase2, word_embeddings, threshold=0.5):\n",
    "    similarity = phrase_similarity(phrase1, phrase2, word_embeddings)\n",
    "    if similarity is not None:\n",
    "        if similarity >= threshold:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        return \"Unable to compute similarity\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification: 0\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "phrase1 = \"weird dude\"\n",
    "phrase2 = \"strange woman\"\n",
    "\n",
    "classification = cosine_phrase_similarity(phrase1, phrase2, word2vec_model_pretrained)\n",
    "print(f\"Classification: {classification}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_cosine = []\n",
    "\n",
    "# Iterate through the test dataset\n",
    "for example in test_data:\n",
    "    phrase1 = example[\"phrase1\"]\n",
    "    phrase2 = example[\"phrase2\"]\n",
    "    similarity_label = example[\"label\"]\n",
    "    prediction = cosine_phrase_similarity(phrase1, phrase2, word2vec_model_pretrained)\n",
    "    predictions_cosine.append((phrase1, phrase2, similarity_label, prediction))\n",
    "\n",
    "\n",
    "# Compute accuracy\n",
    "correct_predictions = sum(1 for _, _, label, pred in predictions_cosine if label == pred)\n",
    "total_predictions = len(predictions_cosine)\n",
    "accuracy = correct_predictions / total_predictions\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.427\n"
     ]
    }
   ],
   "source": [
    "# Generate phrase embeddings for the training dataset\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "i=0\n",
    "train_len = len(train_data)\n",
    "\n",
    "for example in train_data:\n",
    "    if i>train_len//2:\n",
    "      break\n",
    "    i+=1\n",
    "    phrase1_embedding = get_phrase_embedding(example['phrase1'], word2vec_model_pretrained)\n",
    "    phrase2_embedding = get_phrase_embedding(example['phrase2'], word2vec_model_pretrained)\n",
    "\n",
    "    if np.any(phrase1_embedding) and np.any(phrase2_embedding):\n",
    "        combined_embedding = np.concatenate([phrase1_embedding, phrase2_embedding])\n",
    "        features.append(combined_embedding)\n",
    "        labels.append(example['label'])\n",
    "\n",
    "X_train = np.array(features)\n",
    "y_train = np.array(labels)\n",
    "\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "i=0\n",
    "\n",
    "for example in test_data:\n",
    "    phrase1_embedding = get_phrase_embedding(example['phrase1'], word2vec_model_pretrained)\n",
    "    phrase2_embedding = get_phrase_embedding(example['phrase2'], word2vec_model_pretrained)\n",
    "\n",
    "    if np.any(phrase1_embedding) and np.any(phrase2_embedding):\n",
    "        combined_embedding = np.concatenate([phrase1_embedding, phrase2_embedding])\n",
    "        features.append(combined_embedding)\n",
    "        labels.append(example['label'])\n",
    "\n",
    "X_test = np.array(features)\n",
    "y_test = np.array(labels)\n",
    "\n",
    "# Train a Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.4265\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Train an SVM model\n",
    "svm_model = SVC(kernel='linear')\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "\n",
    "# Evaluate the SVM model\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "print(\"SVM Accuracy:\", accuracy_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 31.6/31.6MB downloaded\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import gensim.downloader as api\n",
    "dataset = api.load(\"text8\")\n",
    "data = [i for i in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tagged_document(list_of_list_of_words):\n",
    "   for i, list_of_words in enumerate(list_of_list_of_words):\n",
    "      yield gensim.models.doc2vec.TaggedDocument(list_of_words, [i])\n",
    "\n",
    "training_data = list(tagged_document(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.04832448 -0.16907316 -0.32884434  0.07645246  0.07988791  0.0608741\n",
      " -0.01214247 -0.04433451 -0.30009368  0.06660686  0.13226591 -0.03787967\n",
      " -0.35997528 -0.06874289 -0.17011844  0.01362797  0.08046667  0.01126409\n",
      " -0.08782712 -0.03835297 -0.07367047 -0.01503135 -0.07407348  0.09473714\n",
      " -0.19559278 -0.15877326 -0.25511307 -0.04087844 -0.05472416 -0.174244\n",
      "  0.09895404  0.11550625 -0.29199064 -0.3937337  -0.07769982  0.06879541\n",
      " -0.03918172 -0.20874064  0.03198326 -0.23841998]\n"
     ]
    }
   ],
   "source": [
    "model = gensim.models.doc2vec.Doc2Vec(vector_size=40, min_count=2, epochs=30)\n",
    "model.build_vocab(training_data)\n",
    "model.train(training_data, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "model.save(\"models/doc2vec\")\n",
    "\n",
    "print(model.infer_vector(['violent', 'means', 'to', 'destroy', 'the','organization']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.doc2vec.Doc2Vec.load(\"models/doc2vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector_representation(phrase):\n",
    "    preprocessed_phrase = gensim.utils.simple_preprocess(phrase)\n",
    "    return model.infer_vector(preprocessed_phrase)\n",
    "\n",
    "def get_phrase_cosine_similarty(phrase1, phrase2):\n",
    "    vector1 = get_vector_representation(phrase1)\n",
    "    vector2 = get_vector_representation(phrase2)\n",
    "    return cosine_similarity([vector1], [vector2])[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 0.5075\n"
     ]
    }
   ],
   "source": [
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "similarity_scores=[]\n",
    "for data_entry in test_data:\n",
    "    phrase1 = data_entry[\"phrase1\"]\n",
    "    phrase2 = data_entry[\"phrase2\"]\n",
    "    label = data_entry[\"label\"]\n",
    "\n",
    "    similarity_score = get_phrase_cosine_similarty(phrase1, phrase2)\n",
    "    similarity_scores.append(similarity_score)\n",
    "    threshold = 0.5\n",
    "\n",
    "    # Classify as similar or not based on the threshold\n",
    "    if similarity_score >= threshold:\n",
    "        predicted_label = 1\n",
    "    else:\n",
    "        predicted_label = 0\n",
    "    true_labels.append(label)\n",
    "    predicted_labels.append(predicted_label)\n",
    "\n",
    "\n",
    "    if predicted_label == label:\n",
    "        correct_predictions += 1\n",
    "    total_predictions+=1\n",
    "accuracy = correct_predictions / total_predictions\n",
    "print(f\"Accuracy on the test set: {accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
